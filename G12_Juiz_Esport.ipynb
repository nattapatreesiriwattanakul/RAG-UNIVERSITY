{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nattapatreesiriwattanakul/RAG-UNIVERSITY/blob/main/G12_Juiz_Esport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Requirement"
      ],
      "metadata": {
        "id": "mHfCRRj2j7tS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZzrL5EvhfFs"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-text-splitters langchain-community bs4 neo4j tiktoken langchain-neo4j langchain-huggingface sentence_transformers langchain[google-genai] faiss-cpu pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  print(\"no\")"
      ],
      "metadata": {
        "id": "808swmzKhyO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n"
      ],
      "metadata": {
        "id": "wq8SyISJh2XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "#Neo4J Aura\n",
        "URI = os.environ[\"NEO4J_URI\"] = \"NEO4J URI\"\n",
        "USER = os.environ[\"NEO4J_USERNAME\"] = \"NEO4J USERNAME\"\n",
        "PASSWORD = os.environ[\"NEO4J_PASSWORD\"] = \"NEO4J PASSWORD\"\n",
        "\n",
        "APi_KEY = os.environ[\"GOOGLE_API_KEY\"] = \"GOOGLE API KEY\"\n",
        "\n",
        "driver = GraphDatabase.driver(URI, auth=(USER, PASSWORD))\n",
        "\n",
        "def test_connection():\n",
        "    with driver.session() as session:\n",
        "        r = session.run(\"RETURN 'CONNECTED TO NEO4J AURA' AS msg\")\n",
        "        print(r.single()[\"msg\"])\n",
        "\n",
        "\n",
        "test_connection()\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")"
      ],
      "metadata": {
        "id": "iin0AsLkh0eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
      ],
      "metadata": {
        "id": "SfuJuO2wh-yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "vector_store = FAISS(embedding_function=embeddings, index=index, docstore=InMemoryDocstore(), index_to_docstore_id={})"
      ],
      "metadata": {
        "id": "Bti-rhhDiHnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load data"
      ],
      "metadata": {
        "id": "WMWRi8XqkDf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vS6SZDhTcq5FpX0xSMIxFCDvcmQib60GKFhVKZGZfcJiJ69hU2gOletsbRKXCerww/pub?output=csv\"\n",
        "\n",
        "df_dowloaded = pd.read_csv(csv_path)\n",
        "display(df_dowloaded.head())"
      ],
      "metadata": {
        "id": "-19yEUT8ik4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cleaning Data"
      ],
      "metadata": {
        "id": "YjAi28x8i_tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df_dowloaded.dropna()\n",
        "\n",
        "df_cleaned = df_cleaned.drop_duplicates()\n",
        "\n",
        "print(\"\\n--- Head of the cleaned DataFrame ---\")\n",
        "display(df_cleaned.head())"
      ],
      "metadata": {
        "id": "llGzghS_9fP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Removes leading/trailing whitespace, replaces multiple internal spaces with a single space,\n",
        "    and replaces newline characters with a space.\n",
        "    \"\"\"\n",
        "    if isinstance(text, str):\n",
        "        text = text.strip()\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "        text = text.replace('\\n', ' ')    # Replace newline characters with a space\n",
        "    return text\n",
        "\n",
        "# Define the text columns to clean\n",
        "text_columns = ['Team', 'Role', 'Player', 'Nationality', 'Status']\n",
        "\n",
        "# Apply the cleaning function to each specified text column\n",
        "for col in text_columns:\n",
        "    df_cleaned[col] = df_cleaned[col].apply(clean_text)\n",
        "\n",
        "# Display the first few rows of the cleaned DataFrame\n",
        "display(df_cleaned.head())"
      ],
      "metadata": {
        "id": "yVSXgWzc9qg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Import Dataset to neo4j aura\n"
      ],
      "metadata": {
        "id": "fD6J5KQudZMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Node and Relation"
      ],
      "metadata": {
        "id": "UsTJmspdif4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def import_row(tx, row):\n",
        "    player = row[\"Player\"]\n",
        "    status = row[\"Status\"]\n",
        "    team = row[\"Team\"]\n",
        "    role = row[\"Role\"]\n",
        "    nationality = row[\"Nationality\"]\n",
        "\n",
        "    relation_status = re.sub(r'[^A-Za-z0-9_]', '_', status)\n",
        "\n",
        "    query = f\"\"\"\n",
        "    MERGE (p:Node:ROV_Team {{name: $player}})\n",
        "    MERGE (t:Team {{name: $team}})\n",
        "    MERGE (r:Role {{name: $role}})\n",
        "    MERGE (n:Nationality {{name: $nationality}})\n",
        "\n",
        "    MERGE (p)-[:{relation_status}]->(t)\n",
        "    MERGE (p)-[:played_as]->(r)\n",
        "    MERGE (p)-[:has_nationality]->(n)\n",
        "    \"\"\"\n",
        "\n",
        "    tx.run(query, player=player, team=team, role=role, nationality=nationality)"
      ],
      "metadata": {
        "id": "SigwOTEIcLkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with driver.session() as session:\n",
        "    for idx, row in df_cleaned.iterrows():\n",
        "        session.execute_write(import_row, row)\n",
        "        print(f\"Imported row (Example Player) {idx+1}: Create Node {row['Player']} complete!\")"
      ],
      "metadata": {
        "id": "TgikJrZwfrW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. ทำ Combined Text เพื่อนำไป Storing Vector"
      ],
      "metadata": {
        "id": "_7b6770VjGA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of combined text strings\n",
        "combined_texts = []\n",
        "for index, row in df_cleaned.iterrows():\n",
        "    # Combining 'title', 'predicate', and 'artist' for the music dataset\n",
        "    combined_text = f\"{row['Team']} {row['Role']} {row['Player']} {row['Nationality']} {row['Status']}\"\n",
        "    combined_texts.append(combined_text)\n",
        "\n",
        "# Create a new DataFrame with the combined text\n",
        "df_combined_text = pd.DataFrame({\"combined_text\": combined_texts})\n",
        "\n",
        "# Add auto increment column \"ID\"\n",
        "df_combined_text['ID'] = range(1, len(df_combined_text) + 1)\n",
        "\n",
        "# Display the first and last few rows of the DataFrame\n",
        "display(df_combined_text.head())\n",
        "display(df_combined_text.tail())"
      ],
      "metadata": {
        "id": "QPp563_H9snK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Storing Vector"
      ],
      "metadata": {
        "id": "5yzeQYy_i5Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter, TokenTextSplitter\n",
        "\n",
        "# setting Token Splitter\n",
        "text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "\n",
        "# ดึงข้อมูล Metadata\n",
        "df_combined_text['Team'] = df_cleaned['Team'].values\n",
        "df_combined_text['Role'] = df_cleaned['Role'].values\n",
        "df_combined_text['Player'] = df_cleaned['Player'].values\n",
        "df_combined_text['Nationality'] = df_cleaned['Nationality'].values\n",
        "df_combined_text['Status'] = df_cleaned['Status'].values\n",
        "\n",
        "documents = []\n",
        "\n",
        "# ลูปทีละแถว\n",
        "for index, row in df_combined_text.iterrows():\n",
        "    full_text = row['combined_text']\n",
        "\n",
        "    chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "\n",
        "    if index == 0:\n",
        "        print(f\"\\n--- Example Chunks for first entry (ID: {row['ID']}) ---\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            print(f\"Chunk {i+1}: '{chunk}'\")\n",
        "        print(\"-------------------------------------------\")\n",
        "\n",
        "    # สร้าง Document ให้ครบทุกชิ้นที่หั่นออกมา\n",
        "    for chunk in chunks:\n",
        "        doc = Document(\n",
        "            page_content=chunk,\n",
        "            metadata={\n",
        "                \"id\": row['ID'],\n",
        "                \"team\": row['Team'],\n",
        "                \"role\": row['Role'],\n",
        "                \"player\": row['Player'],\n",
        "                \"nationality\": row['Nationality'],\n",
        "                \"status\": row['Status']\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "\n",
        "# บันทึกเข้า Vector Store\n",
        "document_ids = vector_store.add_documents(documents=documents)\n",
        "\n",
        "print(document_ids[:3])"
      ],
      "metadata": {
        "id": "_50CuBuJJYip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Create RAG Agent with FAISS"
      ],
      "metadata": {
        "id": "k8bEzqaAioJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "\n",
        "def retrieve_context(query: str):\n",
        "  \"\"\"Retrieve information to help answer a query.\"\"\"\n",
        "  retrieved_docs = vector_store.similarity_search(query, k=4)\n",
        "  serialized = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "  return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "V01jQcJfJdAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement RAG Agent"
      ],
      "metadata": {
        "id": "dRC1IliXitxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent\n",
        "tools = [retrieve_context]\n",
        "prompt =( \"\"\"\n",
        "You are a helpful assistant that answers questions using a retrieval tool.\n",
        "\n",
        "You MUST:\n",
        "1. Call `retrieve_context` with the user's query.\n",
        "2. Wait for the tool result.\n",
        "3. After receiving the tool result, generate a FINAL ANSWER for the user.\n",
        "4. DO NOT stop after calling the tool — you must produce a final answer.\n",
        "\n",
        "If the context does not contain the answer, reply:\n",
        "\"I don't have enough information to answer that question.\"\n",
        "\"\"\")\n",
        "agent = create_agent(model, tools, system_prompt=prompt)"
      ],
      "metadata": {
        "id": "t7Jl3yfLKLE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"tell me the name of player who play Role as a Top lane in PSG Esports Team.\"\n",
        "\n",
        "for event in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query}]}, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "UNd5qKQ9KayA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement RAG Chain"
      ],
      "metadata": {
        "id": "Iu4ZMXxfdnRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "\n",
        "@dynamic_prompt\n",
        "def prompt_with_context(request: ModelRequest) -> str:\n",
        "    last_query = request.state[\"messages\"][-1].text\n",
        "    retrieved_docs = vector_store.similarity_search(last_query)\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "    system_message = f\"\"\"You are a helpful assistant that can answer questions based on the following context:\n",
        "\n",
        "{docs_content}\n",
        "\n",
        "Answer the user's question based only on the provided context. If you cannot answer the question based on the context, say \"I don't have enough information to answer that question.\"\n",
        "\"\"\"\n",
        "    return system_message\n",
        "\n",
        "rag_chain_faiss = create_agent(model, tools=[], middleware=[prompt_with_context])"
      ],
      "metadata": {
        "id": "qzOlainCdWxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is a player of Buriram United Esports.\"\n",
        "\n",
        "for step in rag_chain_faiss.stream({\"messages\": [{\"role\": \"user\", \"content\": query}]}, stream_mode=\"values\"):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "hFulO6eudXcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Rag pattern 2 graph db using neo4j document"
      ],
      "metadata": {
        "id": "M_sncBGnbW3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "import os\n",
        "\n",
        "driver = GraphDatabase.driver(\n",
        "    os.environ[\"NEO4J_URI\"],\n",
        "    auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        ")\n",
        "\n",
        "with driver.session() as session:\n",
        "    session.run(\"MATCH (c:Chunk) DETACH DELETE c\")\n",
        "    session.run(\"DROP CONSTRAINT chunk_id_unique IF EXISTS\")\n",
        "    session.run(\"DROP INDEX chunk_id_index IF EXISTS\")"
      ],
      "metadata": {
        "id": "iimH8gX7TzI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_neo4j import Neo4jVector\n",
        "import os\n",
        "\n",
        "db = Neo4jVector.from_documents(\n",
        "    documents, embeddings, url=os.environ[\"NEO4J_URI\"], username=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Jv5Imlq5XtCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def neo4j_retrieve_context(query: str):\n",
        "  \"\"\"Retrieve information from the Neo4j Vector Database to help answer a query.\"\"\"\n",
        "  retrieved_docs = db.similarity_search_with_score(query, k=4)\n",
        "  serialized = \"\\n\\n\".join(\n",
        "      (f\"Source: {doc[0].metadata}\\nContent: {doc[0].page_content}\")\n",
        "      for doc in retrieved_docs\n",
        "  )\n",
        "  return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "9QIEhJ3ZYAbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent\n",
        "neo4j_tools = [neo4j_retrieve_context]\n",
        "prompt = (\"\"\"\n",
        "You are a helpful assistant that answers questions using a retrieval tool.\n",
        "\n",
        "You MUST:\n",
        "1. Call `retrieve_context` with the user's query.\n",
        "2. Wait for the tool result.\n",
        "3. After receiving the tool result, generate a FINAL ANSWER for the user.\n",
        "4. DO NOT stop after calling the tool — you must produce a final answer.\n",
        "\n",
        "If the context does not contain the answer, reply:\n",
        "\"I don't have enough information to answer that question.\"\n",
        "\"\"\")\n",
        "neo4j_agent = create_agent(model, neo4j_tools, system_prompt=prompt)"
      ],
      "metadata": {
        "id": "_SkcwM_DYDH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_neo4j = \"Who is a player of PSG Esports?.\"\n",
        "\n",
        "for event in neo4j_agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query_neo4j}]}, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "F3dda2FKsScH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neo4J Implement RAG Chain"
      ],
      "metadata": {
        "id": "jK4uOs3VttYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "\n",
        "@dynamic_prompt\n",
        "def prompt_with_neo4j_context(request: ModelRequest) -> str:\n",
        "    last_query = request.state[\"messages\"][-1].text\n",
        "    retrieved_docs = db.similarity_search_with_score(last_query, k=4)\n",
        "    docs_content = \"\\n\\n\".join(doc[0].page_content for doc in retrieved_docs)\n",
        "    system_message = f\"\"\"You are a helpful assistant that can answer questions based on the following context:\n",
        "\n",
        "{docs_content}\n",
        "\n",
        "Answer the user's question based only on the provided context. If you cannot answer the question based on the context, say \"I don't have enough information to answer that question.\"\n",
        "\"\"\"\n",
        "    return system_message\n",
        "\n",
        "neo4j_chain = create_agent(model, tools=[], middleware=[prompt_with_neo4j_context])"
      ],
      "metadata": {
        "id": "drm34fdwtsv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_neo4j = \"Who is a player played as a Top Lane in TALON Team.\"\n",
        "\n",
        "for step in neo4j_chain.stream({\"messages\": [{\"role\": \"user\", \"content\": query_neo4j}]}, stream_mode=\"values\"):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "v6ISokH1tyvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Neo4j with triple data using cypher query"
      ],
      "metadata": {
        "id": "ZlbFRiAeYqCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_neo4j import Neo4jGraph, GraphCypherQAChain\n",
        "import os\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=os.environ[\"NEO4J_URI\"],\n",
        "    username=os.environ[\"NEO4J_USERNAME\"],\n",
        "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
        ")\n",
        "\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    model, graph=graph, verbose=True, allow_dangerous_requests=True\n",
        ")\n",
        "\n",
        "chain.run(\"Who is a player of Bacon Time?\")"
      ],
      "metadata": {
        "id": "Tw82zRPcYaNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}